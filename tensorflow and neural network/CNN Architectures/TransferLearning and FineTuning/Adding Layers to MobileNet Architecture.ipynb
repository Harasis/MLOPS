{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import MobileNet\n",
    "\n",
    "#we are transforming already created model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf_no_top.h5\n",
      "17227776/17225924 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = MobileNet(weights = 'imagenet', input_shape = (224,224,3), include_top = False)\n",
    "\n",
    "#here we set our own input_shape\n",
    "#to make the output layer of softmax off so that we can add our own layers at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x22064a25d88>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x2205be98488>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2205be985c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22064a1ab88>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x22064990848>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x220649ed1c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22064acec88>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x22064addf88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22064aedf88>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22064b2f288>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x22064b75988>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x22064b75088>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x220655a7848>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x2206554f7c8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x22065543988>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22065543bc8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22065507a08>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x22064a59908>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x22064ad9b48>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x220648d5fc8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x22064967ec8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2206473fb88>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x220648e8ec8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x22064bf7cc8>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x22064bcf488>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x22064bfed88>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22064c59388>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x22064c59bc8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22064c64648>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22064ca75c8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x22064cf1648>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x22064cf1bc8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22064d74f08>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x22064d7fa88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22064d7c1c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22064dc17c8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x22064e02408>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x22064e02688>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x22064e08688>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22064e8ff88>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x22064e9b8c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22064e9bfc8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22064eddac8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x22064f27548>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x22064f27248>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22064faae48>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x22064fad648>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22064fad6c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22065108688>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2206514cb88>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x2206514cc08>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x220651d5f88>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x220651de288>,\n",
       " <keras.layers.convolutional.Conv2D at 0x220651e1648>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22065223308>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2206526de88>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x22065269548>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x220652f0c08>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x220652f0dc8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x220652fcd48>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x2206533d248>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x22065383348>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x22065383508>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22065406ec8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x22065408c48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22065408248>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22065452a88>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2206549c7c8>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x2206549c048>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22064f0bf08>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x22065268888>,\n",
       " <keras.layers.convolutional.Conv2D at 0x22065268d08>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x220652f6f48>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x2206538d848>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x2206538d608>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x2206540c8c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x2206479b2c8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x220647acf48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x220647acb08>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x2206479b888>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x220658b1c88>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x220658b13c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22065901e88>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x22065907808>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2206591fac8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x22065901d88>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x22065953d08>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(None, 224, 224, 3) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'InputLayer'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].__class__.__name__\n",
    "\n",
    "#To get the name of a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ZeroPadding2D'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].trainable\n",
    "\n",
    "#to check if the layer is trainable or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of layer :  ZeroPadding2D\n",
      "Is is trainable or not : True\n"
     ]
    }
   ],
   "source": [
    "print(\"Name of layer : \", model.layers[1].__class__.__name__ )\n",
    "print(\"Is is trainable or not :\", model.layers[1].trainable )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have to freeze all the layers \n",
    "#We already disable the output layer above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To freeze all the layers\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv_pw_13_relu/Relu6:0' shape=(None, 7, 7, 1024) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output #we disable the softmax outer layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model = model.output\n",
    "\n",
    "#We store this output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv_pw_13_relu/Relu6:0' shape=(None, 7, 7, 1024) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding layers to the end \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "\n",
    "top_model = Dense(1024, activation= 'relu')(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model = Dense(512, activation= 'relu')(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model = Dense(10, activation= 'softmax')(top_model)\n",
    "#this is our own output model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Previous Model that is frozen =  Tensor(\"input_1:0\", shape=(None, 224, 224, 3), dtype=float32)\n",
      "Our New Added Model =  Tensor(\"dense_4/truediv:0\", shape=(None, 7, 7, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Our Previous Model that is frozen = \" , model.input)\n",
    "print(\"Our New Added Model = \", top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining both to create new model\n",
    "\n",
    "new_model = Model(inputs = model.input, outputs = top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7, 7, 1024)        1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7, 7, 512)         524800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7, 7, 10)          5130      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7, 7, 1024)        11264     \n",
      "=================================================================\n",
      "Total params: 4,819,658\n",
      "Trainable params: 1,590,794\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()\n",
    "\n",
    "#our 3 new layers are added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now whenever we fit/train our model only our 3 new layers will get trained \n",
    "#other layer will remain intact because we already freeze them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
